# Reinforcement Learning Course Projects and Homework

This repository contains the projects and homework assignments for the Reinforcement Learning course. Below, each homework is described in detail, showcasing the theoretical and practical components covered throughout the course.

## Homework 1
The first homework focuses on the foundational concepts required for a deeper understanding of reinforcement learning. The theoretical topics include Information Theory, where key concepts like entropy, relative entropy (KL-divergence), and mutual information are explored. Students also dive into Convex Optimization, learning techniques for solving constrained and unconstrained optimization problems, which are critical for understanding algorithms used in RL. Markov Chains are introduced as the basis for modeling sequential decision-making processes. The homework also covers Bayesian Statistics and Estimation Theory, laying the groundwork for probabilistic reasoning and parameter estimation. Finally, Variational Inference is studied, providing tools to approximate complex posterior distributions, which are essential for modern machine learning techniques.

## Homework 2
The second homework extends the theoretical framework to Tabular Markov Decision Processes (MDPs) and Approximation Value Methods, exploring how agents make decisions and learn in finite state and action spaces. On the practical side, students implement fundamental RL algorithms, including Monte Carlo (MC), Temporal Difference (TD), and Q-Learning methods. Advanced variations, such as \( Q(\lambda) \) and SARSA, are also implemented. Additionally, students gain experience with Deep Q-Networks (DQN), bridging the gap between classical methods and modern deep reinforcement learning.

## Homework 3
The third homework introduces Policy Gradient methods, a powerful approach for directly optimizing policies in reinforcement learning. The practical component involves implementing and experimenting with REINFORCE, the foundational algorithm for policy gradients. Students also implement Proximal Policy Optimization (PPO), a popular and robust algorithm used in various state-of-the-art applications.

## Homework 4
The final homework explores advanced topics in reinforcement learning. The theoretical section includes Conservative Q-Learning (CQL), a method for addressing distributional shifts in offline RL; Inverse Reinforcement Learning (IRL), which focuses on learning reward functions from observed behavior; and Bandit Learning, an area emphasizing decision-making under uncertainty. The practical tasks involve implementing Offline RL techniques, such as Soft Actor-Critic (SAC) for continuous action spaces and Behavioral Cloning (BC) to learn policies from demonstrations.

---

## References
- *Reinforcement Learning: An Introduction* by R. Sutton and A. Barto, 2nd Edition, 2020.  
- *Deep Reinforcement Learning* by A. Plaat, 2022.  
- Original papers of some methods.  
- Some slides are adopted from:  
  - CS 285 (Berkeley)  
  - CS 234 (Stanford)  
  - Pieter Abbeelâ€™s compact series on RL.  



